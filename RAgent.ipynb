{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fadcf9b-2dfb-404a-a498-c9daab6e3186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* Running on public URL: https://3c943e773293b3a096.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3c943e773293b3a096.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAgent: AI Co-pilot for R Code\n",
    "\"\"\"\n",
    "This notebook contains a Gradio application that interfaces with both a an AI chat bot and an R code environment.\n",
    "The AI Co-Pilot can read your code and outputs without having to copy paste your code. It can also write suggested code, debug, and analyze your outputs for flaws.\n",
    "Additional use-cases include:\n",
    "\n",
    "- Detecting statistical packages for specialized suggestions.\n",
    "- Generating proposed diff code from suggested changes.\n",
    "- Running R script and previewing generated content.\n",
    "- Handling R script file uploads.\n",
    "\n",
    "RAgent is perfect for beginner and expert coders alike, helping new students learn the R language, and seasoned professionals polish off some ggplot aesthetics.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import gradio as gr\n",
    "import sys\n",
    "import io\n",
    "import subprocess\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Load API key\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Configure AI client\n",
    "model = \"gpt-4o\"\n",
    "client = OpenAI()\n",
    "\n",
    "# Agent logs and code history context\n",
    "agent_logs = []\n",
    "past_code_snippets = []\n",
    "\n",
    "# ------------------------\n",
    "# Package Detection\n",
    "# ------------------------\n",
    "def detect_pkgs(text):\n",
    "    '''\n",
    "    Detects R package usage based on library() code as well as basic code indicators (ex. geom() for ggplot2)\n",
    "\n",
    "    Args:\n",
    "        text (str): User-provided code snippet or chat message\n",
    "\n",
    "    Returns:\n",
    "        str: One of 'lmer', 'ggplot', 'survey', 'lm_glm', or 'general'\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    if \"lmer\" in text or \"lme4\" in text or \"lmertest\" in text:\n",
    "        return 'lmer'\n",
    "    elif \"ggplot\" in text or \"aes\" in text or \"geom_\" in text:\n",
    "        return 'ggplot'\n",
    "    elif \"survey\" in text:\n",
    "        return 'survey'\n",
    "    elif \"lm(\" in text or \"glm(\" in text or \"regression\" in text:\n",
    "        return 'lm_glm'\n",
    "    else:\n",
    "        return 'general'\n",
    "\n",
    "# ------------------------\n",
    "# System Prompt Generation\n",
    "# ------------------------\n",
    "def system_prompt(specialty):\n",
    "    '''\n",
    "    Defines a system prompt to initiate assistant specialty and refuse requests outside of that specialty.\n",
    "\n",
    "    Args:\n",
    "        specialty (str): Key indicating RAgent focus area.\n",
    "\n",
    "    Returns:\n",
    "        str: Full system prompt with specialty.\n",
    "    '''\n",
    "    base = '''You are a helpful assistant that specializes in statistical methods, specifically in R code. \n",
    "    This includes knowledge on the content in standard packages like tidyverse and dplyer as well as more advanced packages like lmerTest.\n",
    "    Your job is to help beginners to experts and students to professors alike in choosing accurate statistical methods and packages for their projects. \n",
    "    If the user is unsure what piece of code to write or statistical method to use, you will ask for context on their project, including dataset information and outcome expectations, as well as desired significance, applications, and relationships of variables.\n",
    "    Any suggestions you give should be on a case-by-case basis, meaning you will suggest code for one test at a time. In any case scenario, you MUST stick to one statistical test at a time. \n",
    "    Be assertive in confirming if a single piece of code works before seeing if further results or plots should be made. \n",
    "    Ask for a copy of the output if you are unsure that the user has failed in conducting the test accurately. \n",
    "    If the user asks for multiple pieces of code, you will start with the first request and ensure that there are no bugs and a useful outcome is obtained before moving to the next requested code. \n",
    "    If a user is asking for explanations of the outcomes for a statistical method they have already coded, please make sure you understand all of the input variables as well as any fine tuning that was done before creating a confident response of what the outcome means in terms of the project. \n",
    "    You will also ask if a writeup should be made in any particular format (bullet points, paragraph, outline) to illuminate the meaning behind the outcome. \n",
    "    Let's walk through an example. If a user sends the outputs of a regression model lm(), you should confirm what the user is looking to find and/or the variables included in the experiment before selecting a top few findings in the regression results to highlight in the context of the experiment. \n",
    "    That means creating a brief response with a very specific and confident main point centered around one or two of the regression findings. If the user asks for more explanations, you may give it but your initial response should be concise and confident. \n",
    "    When the user asks you to explain an output, you should focus about being direct and assertive towards what the numerical outputs in the linear model explain in regards to the variables tested. \n",
    "    This means immediately pointing out significance, fixed effects, or potential issues in the model before explaining anything regarding definitions, or how a linear regression actually works. \n",
    "    Your focus should be on brevity with smart suggestions and intelligent insights. Try your best to be witty but useful.\n",
    "    If the user does something incorrectly, you should be brief and responsive, highlighting the immediate fix before asking clarification questions if you are unsure what the exact issue is.\n",
    "    Your questions and responses should be assertive. Do not explain anything that was not asked to be explain and try to keep up with the expected knowledge of the user before explaining introductory or advanced concepts. \n",
    "    You may ask an introductory question about the users experience level with the requested analysis or code or dataset if you are unsure whether or not you are explaining concepts that are already understood. To make it clear, a user could ask for assistance with a piece of code but still be completely knowledgeable about the concept or topic.\n",
    "    If the user asks about ANYTHING other than R code related questions, INCLUDING THAT OF OTHER CODING LANGUAGES, you MUST response with 'I'm sorry, do you have any questions related to your R code that I can help with?'. The user is permitted to ask about the R coding language and any packages without code existing as context (ex. \"What is the shiny library\", \"What is ggplot\", \"What is R\").\n",
    "    You shall not engage in any misconduct related to behavior outside of R code questions. If you figure out you have been mislead to talk about a different topic, please immediately revert to the apology statement asking if you can help with any R code.\n",
    "    If you are unsure, it's better to stay on the side of caution rather than engage in misconduct. However, the user will get annoyed if you are refusing to answer their questions about R or R packages. \n",
    "\n",
    "    At the end of the day, please emphasize CONCISE answers. THAT MEANS ONE OR TWO SENTENCES PER ANSWER WHERE AT ALL POSSIBLE! LESS IS BETTER! The user has some of the answers and does not need you to answer beyond what their basic ask is. If they want a solution, provide the most simple and efficient one without any fluff of language or description. \n",
    "    The user can and will ask for elaboration but does not need you to explain in depth unless asked for.\n",
    "    '''\n",
    "\n",
    "    # Defining the system prompt based on package detection\n",
    "    if specialty == 'lmer':\n",
    "        base = base.replace(\"specifically in R code\", \"specifically in R code, with an emphasis on mixed models and the lme4/lmerTest packages\")\n",
    "    elif specialty == 'ggplot':\n",
    "        base = base.replace(\"specifically in R code\", \"specifically in R code, with a specialization in data visualization using ggplot2\")\n",
    "    elif specialty == 'survey':\n",
    "        base = base.replace(\"specifically in R code\", \"specifically in R code, with a focus on complex survey design and the survey package\")\n",
    "    elif specialty == 'lm_glm':\n",
    "        base = base.replace(\"specifically in R code\", \"specifically in R code, with a particular emphasis on linear and generalized linear models\")\n",
    "    return base\n",
    "\n",
    "# ------------------------\n",
    "# Code Extraction and Diffs\n",
    "# ------------------------\n",
    "def extract_code(text):\n",
    "    \"\"\"\n",
    "    Extract R code snippets from RAgent-generated text.\n",
    "\n",
    "    Args:\n",
    "        text (str): RAgent's message.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of extracted code snippets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Try and find fenced R code\n",
    "    matches = re.findall(r\"```{r*+}```\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if matches:\n",
    "        return [m.strip() for m in matches]\n",
    "\n",
    "    # Extract common R commands \n",
    "    matches = re.findall(r\"(library\\(.*?\\)|ggplot\\(.*?\\)|data\\(.*?\\)|.+?%>%)\", text)\n",
    "    return [m.strip() for m in matches]\n",
    "\n",
    "# diff agent\n",
    "def llm_generate_diff(old_code, new_code):\n",
    "    \"\"\"\n",
    "    Compare two R scripts and summarize major changes.\n",
    "\n",
    "    Args:\n",
    "        old_code (str): Original R script content.\n",
    "        new_code (str): Proposed updated R script content.\n",
    "\n",
    "    Returns:\n",
    "        str: Summary of differences.\n",
    "    \"\"\"\n",
    "    model = \"gpt-4.1\"\n",
    "    diff_prompt = f\"\"\"You are an assistant that detects and summarizes the important changes between two versions of R code.\n",
    "\n",
    "Compare the following two R scripts:\n",
    "\n",
    "OLD CODE:\n",
    "{old_code}\n",
    "\n",
    "NEW CODE:\n",
    "{new_code}\n",
    "\n",
    "First, list the MAJOR differences clearly.\n",
    "Then, suggest a compact R code diff if possible.\n",
    "\n",
    "Be precise, and focus on meaning changes, not just formatting. Ensure that all suggested code is accurately captured in the diff changes.\n",
    "If the two scripts are completely different, just explain the high-level changes instead of showing line-by-line diff.\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You compare R code versions and detect meaningful changes.\"},\n",
    "                  {\"role\": \"user\", \"content\": diff_prompt}],\n",
    "        n=1,\n",
    "        temperature=0.1,\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "def apply_diff(current_code, proposed_code):\n",
    "    \"\"\"\n",
    "    Replace the current code with the proposed code after approval.\n",
    "\n",
    "    Args:\n",
    "        current_code (str): Existing R script.\n",
    "        proposed_code (str): Full updated R script.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, gr.Update]: Updated script and UI update for replace button.\n",
    "    \"\"\"\n",
    "    updated_code = proposed_code.strip()\n",
    "    past_code_snippets.append(updated_code)\n",
    "    agent_logs.append({\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"action\": \"apply_diff\",\n",
    "        \"inserted_code\": updated_code\n",
    "    })\n",
    "    return updated_code, gr.update(visible=False)\n",
    "\n",
    "# ------------------------\n",
    "# RAgent Core\n",
    "# ------------------------\n",
    "def ask_ragent(user_msg, history, current_code, console_output):\n",
    "    \"\"\"\n",
    "    Send user message and context to RAgent, receive advice or code suggestions.\n",
    "\n",
    "    Args:\n",
    "        user_msg (str): Current user question or request.\n",
    "        history (list): Chat history for context.\n",
    "        current_code (str): The R script currently in the editor.\n",
    "        console_output (str): Last run output from the R console.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, list, str, gr.Update]: Cleared input box, updated history, proposed snippet, and confirm button visibility.\n",
    "    \"\"\"\n",
    "    \n",
    "    old_code = current_code.strip() if current_code else \"\"\n",
    "    #context_code = \"\\n\\n\".join(past_code_snippets[-3:]) + \"\\n\\n\" + current_code\n",
    "    specialty = detect_pkgs(old_code + \" \" + user_msg)\n",
    "    agent_prompt = system_prompt(specialty)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": agent_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Here's my current code:\\n{old_code}\\nConsole output:\\n{console_output}\\n{user_msg}\"}\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        n=1,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    reply = completion.choices[0].message.content\n",
    "\n",
    "    # Generate diffs\n",
    "    diff_summary = \"\"\n",
    "    proposed = \"\"\n",
    "    code_blocks = extract_code(reply)\n",
    "    if code_blocks:\n",
    "        proposed = code_blocks[0]\n",
    "        diff_summary = llm_generate_diff(old_code, proposed)\n",
    "        #reply += f\"\\n\\n---\\nHere’s the diff between your current code and the proposed changes:\\n{diff_summary}\"\n",
    "\n",
    "    show_confirm = bool(proposed)\n",
    "\n",
    "    # Agent hand-off logs\n",
    "    agent_logs.append({\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"specialty\": specialty,\n",
    "        \"user_msg\": user_msg,\n",
    "        \"proposed_code\": proposed,\n",
    "        \"diff_summary\": diff_summary,\n",
    "        \"code_detected\": bool(proposed)\n",
    "    })\n",
    "\n",
    "    # Update chat history and UI\n",
    "    history.append({\"role\": \"user\", \"content\": user_msg})\n",
    "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return \"\", history, proposed, gr.update(visible=show_confirm)\n",
    "\n",
    "# ------------------------\n",
    "# R Script\n",
    "# ------------------------\n",
    "def run_r(code):\n",
    "    \"\"\"\n",
    "    Execute R code via Rscript and save any plots.\n",
    "\n",
    "    Writes the provided R code to a temporary file, appends a ggsave call to export a plot to 'plot.png',\n",
    "    then runs the script using Rscript. Captures stdout and stderr, checks for plot existence, and returns results.\n",
    "\n",
    "    Args:\n",
    "        code (str): R code to execute.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            output (str): Combined stdout and stderr from Rscript.\n",
    "            code (str): Original R code.\n",
    "            output (str): Duplicate console output for compatibility.\n",
    "            plot_path (str | None): Path to 'plot.png' if generated, else None.\n",
    "    \"\"\"\n",
    "    with open(\"temp_code.R\", \"w\") as f:\n",
    "        f.write(code + \"\\n\\nggsave('plot.png', width=6, height=4)\")\n",
    "    try:\n",
    "        result = subprocess.run([\"Rscript\", \"temp_code.R\"], capture_output=True, text=True, timeout=10)\n",
    "        output = result.stdout + \"\\n\" + result.stderr\n",
    "        plot_exists = os.path.exists(\"plot.png\")\n",
    "    except Exception as e:\n",
    "        output = f\"Error running R script: {e}\"\n",
    "        plot_exists = False\n",
    "    return output, code, output, \"plot.png\" if plot_exists else None\n",
    "\n",
    "# Handle setting working directory\n",
    "def set_working_dir(path):\n",
    "    \"\"\"\n",
    "    Change Python’s working directory (where temp_code.R is created & run).\n",
    "    Returns a status message for the UI.\n",
    "    \"\"\"\n",
    "    if path and os.path.isdir(path):\n",
    "        os.chdir(path)\n",
    "        return f\"Working directory set to:\\n{os.getcwd()}\"\n",
    "    else:\n",
    "        return f\"Invalid directory: {path!r}\"\n",
    "\n",
    "# upload R files\n",
    "def handle_files(file):\n",
    "    if not file.name.endswith(\".R\"):\n",
    "        return \"\", \"Error: Only .R files are supported.\"\n",
    "\n",
    "    try:\n",
    "        code = open(file.name).read()\n",
    "        return code, code\n",
    "    except Exception as e:\n",
    "        return \"\", f\"Failed to read file: {str(e)}\"\n",
    "\n",
    "def confirm_file(file):\n",
    "    if file is None:\n",
    "        return \"\", gr.update(visible=False), None\n",
    "    try:\n",
    "        with open(file.name, \"r\") as f:\n",
    "            code = f.read()\n",
    "        print(\"File received:\", file.name if file else \"None\")\n",
    "        return code, gr.update(visible=False), None\n",
    "    except Exception as e:\n",
    "        return \"\", f\"Failed to confirm file: {str(e)}\", None\n",
    "\n",
    "# Export for agent logs\n",
    "def export_logs():\n",
    "    if not agent_logs:\n",
    "        return None\n",
    "    df = pd.DataFrame(agent_logs)\n",
    "    df.to_csv(\"agent_logs.csv\", index=False)\n",
    "    return \"agent_logs.csv\"\n",
    "\n",
    "# UI\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"RAgent\")\n",
    "    code_history = gr.State(\"\")\n",
    "    console_history = gr.State(\"\")\n",
    "    proposed_code = gr.State(\"\")\n",
    "    chat_state = gr.State([])\n",
    "    file = gr.State()\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            file_input = gr.File(label=\"Upload R Script\", file_types=[\".R\"])\n",
    "            code_input = gr.Code(language=\"r\", label=\"Enter R code\")\n",
    "            run_button = gr.Button(\"Run Code\")\n",
    "            code_output = gr.Textbox(label=\"Console Output\", lines=10)\n",
    "            plot_output = gr.Image(type=\"filepath\", label=\"Plot Preview\")\n",
    "            file_input.change(\n",
    "                fn=handle_files, \n",
    "                inputs=file_input,\n",
    "                outputs=[code_input, code_history]\n",
    "            )\n",
    "            code_input.change(\n",
    "                fn=lambda code: code,\n",
    "                inputs=[code_input],\n",
    "                outputs=[code_history]\n",
    "            )\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            chatbot = gr.Chatbot(label=\"RAgent Assistant\", type=\"messages\", value=[\n",
    "                {\"role\": \"assistant\", \"content\": \"Hello! How can I assist your coding today?\"}])\n",
    "            chat_input = gr.Textbox(label=\"Ask a question or request help\")\n",
    "            send_button = gr.Button(\"Send Message\")\n",
    "            confirm_button = gr.Button(\"Add Code\", visible=False)\n",
    "            replace_button = gr.Button(\"Replace Lines\", visible=False)\n",
    "\n",
    "    run_button.click(run_r, inputs=code_input, outputs=[code_output, code_history, console_history, plot_output])\n",
    "    send_button.click(ask_ragent, inputs=[chat_input, chat_state, code_history, console_history], outputs=[chat_input, chatbot, proposed_code, confirm_button])\n",
    "    confirm_button.click(apply_diff, inputs=[code_input, proposed_code], outputs=[code_input, confirm_button])\n",
    "\n",
    "    # Agent logs\n",
    "    #with gr.Row():\n",
    "    #    log_export = gr.Button(\"Export Logs\")\n",
    "    #    log_output = gr.File(label=\"Download Logs\")\n",
    "    #    log_export.click(fn=export_logs, inputs=[], outputs=log_output)\n",
    "\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755d9b9-d8d3-4d7b-b321-a48db5000fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
